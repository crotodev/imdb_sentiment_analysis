{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:06.237284Z",
     "start_time": "2024-02-09T22:38:00.225678Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")[\"train\"].train_test_split(test_size=0.225, train_size=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351c9ac07b566f6b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:06.281344200Z",
     "start_time": "2024-02-09T22:38:06.237284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   text  label\n0     After reading only two of the comments herein,...      1\n1     Let me state at the outset that I have Cerebra...      1\n2     I'm not tired to say this is one of the best p...      1\n3     To be a Buster Keaton fan is to have your hear...      0\n4     I don't usually write a comment when there are...      0\n...                                                 ...    ...\n6245  Since Douglas MacArthur affected more human li...      1\n6246  This is an important film. It challenges the v...      1\n6247  Jack Frost, no kids it's not the warm hearted ...      0\n6248  I watched this movie with some friends a coupl...      0\n6249  I love this show and my 11 year-old daughter a...      1\n\n[6250 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>After reading only two of the comments herein,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Let me state at the outset that I have Cerebra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I'm not tired to say this is one of the best p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To be a Buster Keaton fan is to have your hear...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I don't usually write a comment when there are...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6245</th>\n      <td>Since Douglas MacArthur affected more human li...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6246</th>\n      <td>This is an important film. It challenges the v...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6247</th>\n      <td>Jack Frost, no kids it's not the warm hearted ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6248</th>\n      <td>I watched this movie with some friends a coupl...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6249</th>\n      <td>I love this show and my 11 year-old daughter a...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6250 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65ba8995befbc2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:13.719927300Z",
     "start_time": "2024-02-09T22:38:06.282346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/12500 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ea380208c8c45228ea2ec152f54cc57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/6250 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77e14f14f37a4037bc3cfd55213791e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(data):\n",
    "    return tokenizer(data[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c82438265ba2b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:15.836356900Z",
     "start_time": "2024-02-09T22:38:13.720931700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd019a8656c5c8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:16.456211200Z",
     "start_time": "2024-02-09T22:38:15.839384500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=750,\n",
    "    logging_dir=\"./imdb_logs\",\n",
    "    logging_steps=10,\n",
    "    save_steps=1000,\n",
    "    output_dir=\"./imdb_results\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a792ba586876b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T22:38:20.693941700Z",
     "start_time": "2024-02-09T22:38:18.193906800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='9375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/9375 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: './imdb_results\\\\tmp-checkpoint-5' -> './imdb_results\\\\checkpoint-5'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\ml_sentiment_analysis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1537\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1535\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1537\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1538\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1539\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1540\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1542\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\ml_sentiment_analysis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1914\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1911\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch \u001B[38;5;241m+\u001B[39m (step \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m steps_skipped) \u001B[38;5;241m/\u001B[39m steps_in_epoch\n\u001B[0;32m   1912\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_step_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 1914\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1915\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1916\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_substep_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\ml_sentiment_analysis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2279\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2276\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mstep(metrics[metric_to_check])\n\u001B[0;32m   2278\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_save:\n\u001B[1;32m-> 2279\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_save_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2280\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_save(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\GitHub\\ml_sentiment_analysis\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2395\u001B[0m, in \u001B[0;36mTrainer._save_checkpoint\u001B[1;34m(self, model, trial, metrics)\u001B[0m\n\u001B[0;32m   2391\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mmain_process_first(\n\u001B[0;32m   2392\u001B[0m         desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRenaming model checkpoint folder to true location\u001B[39m\u001B[38;5;124m\"\u001B[39m, local\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39msave_on_each_node\n\u001B[0;32m   2393\u001B[0m     ):\n\u001B[0;32m   2394\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(staging_output_dir):\n\u001B[1;32m-> 2395\u001B[0m             \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrename\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstaging_output_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2397\u001B[0m \u001B[38;5;66;03m# Maybe delete some older checkpoints.\u001B[39;00m\n\u001B[0;32m   2398\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mshould_save:\n",
      "\u001B[1;31mPermissionError\u001B[0m: [WinError 5] Access is denied: './imdb_results\\\\tmp-checkpoint-5' -> './imdb_results\\\\checkpoint-5'"
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e297efc55cdb9b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T19:42:41.766133Z",
     "start_time": "2023-11-29T19:42:40.001680Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./sentiment_pos_neg/tokenizer_config.json',\n",
       " './sentiment_pos_neg/special_tokens_map.json',\n",
       " './sentiment_pos_neg/vocab.txt',\n",
       " './sentiment_pos_neg/added_tokens.json',\n",
       " './sentiment_pos_neg/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./imdb-sentiment\")\n",
    "tokenizer.save_pretrained(\"./imdb-sentiment_pos_neg\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ef0668e1993639d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
